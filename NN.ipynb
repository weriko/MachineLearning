{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dc6f94f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#Added logistic\n",
    "#Add regressor\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, layer_sizes, layer_activations, epsilon = 0.1, lr=0.01):\n",
    "        self.epsilon = epsilon\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.layer_activations = layer_activations\n",
    "        self.initialize()\n",
    "        self.lr = lr\n",
    "        self.activation_functions = {\n",
    "            \"relu\":self.relu,\n",
    "            \"sigmoid\":self.sigmoid,\n",
    "            \"grelu\":self.grelu,\n",
    "            \"gsigmoid\":self.gsigmoid            \n",
    "            \n",
    "            }\n",
    "        \n",
    "    def initialize(self):\n",
    "        self.W = [] #NN weights\n",
    "        self.b = [] #NN betas\n",
    "        for i in range(len(self.layer_sizes)-1):\n",
    "            self.W.append(np.random.randn(self.layer_sizes[i+1],self.layer_sizes[i]  )*self.epsilon) #Randomly initializes weights for all layers \n",
    "            self.b.append(np.random.randn(self.layer_sizes[i+1],1)*self.epsilon) #Randomly initializes betas for all layers \n",
    "            #print(self.W[i])\n",
    "        \n",
    "    def sigmoid(self,x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    \n",
    "    \n",
    "    def gsigmoid(self,da,x):\n",
    "        temp = self.sigmoid(x)\n",
    "   \n",
    "        return da * temp * (1-temp)\n",
    "    \n",
    "    \n",
    "    def relu(self,x):\n",
    "        return np.maximum(0,x)\n",
    "    def grelu(self,da,x):\n",
    "\n",
    "        temp = np.array(da, copy=True)\n",
    "        temp[x<=0] = 0\n",
    "        return temp\n",
    "    \n",
    "\n",
    "    def propagate(self,x,is_pred=False):\n",
    "        cacheW = []\n",
    "     \n",
    "        z = x.T\n",
    "       \n",
    "      \n",
    "        #print(z)\n",
    "        a = self.activation_functions[self.layer_activations[0]](z)\n",
    "        \n",
    "        \n",
    "        for i in range(len(self.W)):\n",
    "            cacheW.append((a,z))\n",
    "            #print(self.W[i].shape)\n",
    "        \n",
    "           \n",
    "\n",
    "           \n",
    "            z = np.dot(self.W[i], a ) + self.b[i]\n",
    "            #print(self.b[i].shape)\n",
    "           \n",
    "            a = self.activation_functions[self.layer_activations[i]](z)\n",
    "            #print(a.shape)\n",
    "            assert(a.shape == z.shape)\n",
    "        cacheW.append((a,z))\n",
    "\n",
    "        if not is_pred:       \n",
    "            \n",
    "            self.cache =  cacheW\n",
    "        else:\n",
    "            return cacheW[-1][0]\n",
    "  \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def backpropagate(self,y,y_pred):\n",
    "        gradsW = []\n",
    "        gradsb= []\n",
    "     \n",
    "        \n",
    "        #print(y.shape, y_pred.shape)\n",
    "        da= -(np.divide(y,y_pred+self.epsilon) - np.divide(1-y,1-y_pred+self.epsilon))\n",
    "        #print(da.shape)\n",
    "        \n",
    "       \n",
    "        for i in range(len(self.W))[::-1]:\n",
    "            \n",
    "            \n",
    "          \n",
    "            \n",
    "            a_prev =  self.cache[i][0]\n",
    "            #print(a.shape)\n",
    "            \n",
    "            #print(self.cache[0][0].shape)\n",
    "           \n",
    "          \n",
    "           \n",
    "            z = self.cache[i+1][1] #Need to get the z for the next layer\n",
    "            #print(z.shape)\n",
    "            #print(a.shape)\n",
    "            \n",
    "            w = self.W[i]\n",
    "          \n",
    "            b = self.b[i]\n",
    "            \n",
    "            dz = self.activation_functions[\"g\"+self.layer_activations[i]](da,z)\n",
    "          \n",
    "            #print(dz.shape)\n",
    "            #print(a.shape)\n",
    "            \n",
    "            \n",
    "         \n",
    "            \n",
    "            dw = np.dot(dz, a_prev.T)/a_prev.shape[1]\n",
    "            \n",
    "            db = np.sum(dz, axis=1,keepdims=True)/a_prev.shape[1]\n",
    "           \n",
    "        \n",
    "            #print(dw.shape)\n",
    "           \n",
    "            da = np.dot(w.T, dz)\n",
    "            \n",
    "            #print(a.shape)\n",
    "           \n",
    "            #print(dw)\n",
    "            \n",
    "            gradsW.append(dw)\n",
    "            gradsb.append(db)\n",
    "            \n",
    "        self.gradsw = gradsW\n",
    "        self.gradsb = gradsb\n",
    "        \n",
    "    def update(self):\n",
    "        \n",
    "       \n",
    "        \n",
    "       \n",
    "        for i in range(len(self.gradsw)):\n",
    "            #print(self.gradsw[i])\n",
    "            #print(self.gradsw[i].shape)\n",
    "         \n",
    "           \n",
    "            self.W[i] -= self.lr*self.gradsw[-(i+1)] #It updates the weights of the first layer, second layer... the grads lists are inverted because of the way they were stored (last first)\n",
    "            self.b[i] -= self.lr*self.gradsb[-(i+1)]\n",
    "        #print(self.W[-1])\n",
    "          \n",
    "            \n",
    "    def fit(self,x,y,epochs=1):\n",
    "        for i in range(epochs):\n",
    "            self.propagate(x)\n",
    "            self.backpropagate(y,self.cache[-1][0])\n",
    "            self.update()\n",
    "            \n",
    "    def predict(self,x):\n",
    "        a =self.propagate(x,is_pred=True)\n",
    "        return a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "36016af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f8dbd46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\Weriko\\\\source\\\\repos\\\\MachineLearning\\MachineLearning\\\\train_mod2.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "59deec10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7985074626865671\n",
      "Wall time: 2.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X = df[[\"Pclass\",\"Sex\",\"Age\",\"Fare\"]].to_numpy()\n",
    "y = df[\"Survived\"].to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "   X, y, test_size=0.15, random_state=42)\n",
    "NN = NeuralNetwork((4,6,4,1),(\"relu\",\"relu\",\"sigmoid\"), lr =0.01)\n",
    "#print(NN.W)\n",
    "NN.fit(X_train,y_train,epochs = 10000)\n",
    "\n",
    "\n",
    "ypreds = np.array([0 if i <0.5 else 1 for i in NN.predict(X_test)[0]])\n",
    "#print(NN.predict(X_test))\n",
    "print(sum(ypreds==y_test)/y_test.shape[0])\n",
    "#print(NN.W) \n",
    "#print(NN.b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ff47a245",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f3243f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7313432835820896\n",
      "Wall time: 157 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, max_iter=10000,\n",
    "                     hidden_layer_sizes=(6, 4))\n",
    "clf.fit(X_train,y_train)\n",
    "skypreds = clf.predict(X_test)\n",
    "print(sum(skypreds==y_test)/y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3686f114",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
